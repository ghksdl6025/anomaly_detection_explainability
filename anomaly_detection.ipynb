{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc129d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34472358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_prefix(df,prefix):\n",
    "    '''\n",
    "    Filter case by prefix length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to slice by prefix length\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe with sliced cases\n",
    "    '''\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        if len(group)>prefix:\n",
    "            group = group.loc[:prefix-1,:]\n",
    "            encoded_df.append(group)\n",
    "    return pd.concat(encoded_df)\n",
    "\n",
    "def indexbase_encoding(df, prefix):\n",
    "    '''\n",
    "    Indexbase encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to encode for outcome prediction\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe encoded in indexbase method\n",
    "    '''\n",
    "    df = filter_by_prefix(df,prefix)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    if 'resource' not in list(df.columns.values):\n",
    "        noresource = True\n",
    "    else:\n",
    "        noresource = False\n",
    "        \n",
    "    for case,group in groups: \n",
    "        activitylist = list(group['activity'])\n",
    "        \n",
    "        group = group.reset_index(drop=True)\n",
    "        outcome = set(group['outcome']).pop()\n",
    "        cumdurationlist = [(x - list(group['ts'])[0]).total_seconds() for x in list(group['ts'])]\n",
    "        cumduration_index ={'Cumduration_'+str(x+1): cumdurationlist[x] for x in range(len(cumdurationlist))}\n",
    "        \n",
    "        case_outcome = {'caseid':case, 'outcome':outcome}\n",
    "        activity_index = {'activity_'+str(x+1)+'_'+activitylist[x]: 1 for x in range(len(activitylist))}\n",
    "\n",
    "        if noresource == False:\n",
    "            resourcelist = list(group['resource'])\n",
    "            resource_index = {'resource_'+str(x+1)+'_'+str(resourcelist[x]): 1 for x in range(len(resourcelist))}\n",
    "            case_outcome.update(resource_index)\n",
    "        \n",
    "        case_outcome.update(cumduration_index)\n",
    "        case_outcome.update(activity_index)\n",
    "        dfk = pd.DataFrame.from_dict([case_outcome])\n",
    "        encoded_df.append(dfk)\n",
    "    concated_df = pd.concat(encoded_df)\n",
    "    concated_df = concated_df.fillna(0)\n",
    "    return concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c9d6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./preprocessed_loan_baseline.pnml_noise_0.049999999999999996_iteration_1_seed_42477_sample.csv')\n",
    "\n",
    "\n",
    "key_pair = {'Case ID':'caseid', 'Activity':'activity', 'Complete Timestamp':'ts'}\n",
    "df = df.rename(columns=key_pair)\n",
    "\n",
    "if 'resource' in df.columns.values:\n",
    "    df = df.loc[:,['caseid','activity','ts','resource','noise']]\n",
    "\n",
    "else:\n",
    "    df = df.loc[:,['caseid','activity','ts','noise']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "744e33a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       NaN\n",
      "1       NaN\n",
      "2       NaN\n",
      "3       NaN\n",
      "4       NaN\n",
      "       ... \n",
      "6625    NaN\n",
      "6626    NaN\n",
      "6627    NaN\n",
      "6628    NaN\n",
      "6629    NaN\n",
      "Name: noise, Length: 6630, dtype: object\n"
     ]
    }
   ],
   "source": [
    "groups = df.groupby('caseid')\n",
    "concating = []\n",
    "max_case_len = max([len(group) for _, group in groups])\n",
    "caseids = list(set(df['caseid']))\n",
    "\n",
    "outcome = []\n",
    "for _, group in groups:\n",
    "    group = group.reset_index(drop=True)\n",
    "    actlist = list(group['activity'])\n",
    "    outcomelist = actlist[1:] + [np.nan]\n",
    "    group['outcome'] = outcomelist\n",
    "    concating.append(group)\n",
    "\n",
    "dfn = pd.concat(concating)\n",
    "\n",
    "max_case_len =10\n",
    "idslist = []\n",
    "for prefix in range(1, max_case_len):\n",
    "    idslist.append(indexbase_encoding(dfn,prefix))\n",
    "\n",
    "prefixlist= list(range(1, max_case_len))\n",
    "acc_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e59c574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest\n"
     ]
    }
   ],
   "source": [
    "print('Random forest')\n",
    "models = []\n",
    "used_models = 'RF'\n",
    "testdf_list = []\n",
    "\n",
    "for pos,prefix in enumerate(idslist):\n",
    "    np.random.seed(2022)\n",
    "    trainids = np.random.choice(caseids, int(len(caseids)*0.7), replace=False)\n",
    "\n",
    "    traindf = prefix[prefix['caseid'].isin(trainids)].reset_index(drop=True)\n",
    "    testdf = prefix[~prefix['caseid'].isin(trainids)].reset_index(drop=True)\n",
    "    testdf_list.append(testdf)\n",
    "\n",
    "    y_train = traindf['outcome']\n",
    "    x_train = traindf.drop(columns=['outcome','caseid'],axis=1)\n",
    "\n",
    "    y_test = testdf['outcome']\n",
    "    x_test = testdf.drop(columns=['outcome','caseid'],axis=1)\n",
    "\n",
    "    # Random forest result    \n",
    "    \n",
    "    rf = RandomForestClassifier(criterion='entropy').fit(x_train,y_train)\n",
    "    y_pred = rf.predict(x_test)\n",
    "\n",
    "    filename = './models/%s prefix %s.pkl'%(used_models, pos+1)\n",
    "    models.append(rf)\n",
    "    with open(filename,'wb') as f:\n",
    "        pkl.dump(rf, f)\n",
    "\n",
    "    acc_dict['prefix_%s'%(str(prefixlist[pos]))] =  accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d0b3222",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_case_ids = set(testdf_list[-1]['caseid'])\n",
    "testdf = df[df['caseid'].isin(testing_case_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9fbedc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[-1]\n",
    "for_confusion_matrix = {}\n",
    "\n",
    "counting_normal = 0\n",
    "ad_predictions=[]\n",
    "ad_true = []\n",
    "for threshold in [0.01,0.05,0.1,0.15,0.2,0.25]:\n",
    "    global_true =[]\n",
    "    global_pred = []\n",
    "\n",
    "    for pos, prefix in enumerate(idslist):\n",
    "\n",
    "        for_confusion_matrix[int(caseid)] =[]\n",
    "        prediction_list = []\n",
    "        df = testdf\n",
    "        \n",
    "        for caseid in list(testing_case_ids):\n",
    "            prediction_label = 'Normal'\n",
    "            x_test = testdf_list[pos][testdf_list[pos]['caseid'] ==caseid]\n",
    "            true_outcome = x_test['outcome'].values[0]\n",
    "            \n",
    "            x_test_features = list(x_test.columns.values)\n",
    "            x_test_features.remove('caseid')\n",
    "            x_test_features.remove('outcome')\n",
    "            \n",
    "            x_test = x_test.loc[:, x_test_features]\n",
    "            x_test = np.array(x_test.values).reshape(1,-1)\n",
    "\n",
    "            model_classes = models[pos].classes_\n",
    "            predictions_proba = models[pos].predict_proba(x_test)[0]\n",
    "            predicted_one = model_classes[np.argmax(predictions_proba)]\n",
    "        \n",
    "            if predicted_one  == 'Not Available':\n",
    "                prediction_label = 'Not Available'\n",
    "            else:\n",
    "                if true_outcome in model_classes:\n",
    "                    labelidx = list(model_classes).index(true_outcome)\n",
    "\n",
    "                    if predictions_proba[labelidx] <threshold:\n",
    "                        prediction_label = 'Anomalous'\n",
    "                else:\n",
    "                    prediction_label = 'Anomalous'\n",
    "            \n",
    "            noisedf = df[df['caseid'] == caseid].reset_index(drop=True)\n",
    "            noiselabel = list(noisedf['noise'])[pos]\n",
    "            if np.isnan(noiselabel):\n",
    "                noiselabel= 'Normal'\n",
    "            else:\n",
    "                noiselabel= 'Anomalous'\n",
    "            ad_predictions.append(prediction_label)\n",
    "            ad_true.append(noiselabel)\n",
    "        \n",
    "    #     for pos, p in enumerate(prediction_list):\n",
    "    #         global_pred.append(p)\n",
    "    #         global_true.append(true_label_list[pos])\n",
    "\n",
    "\n",
    "    # saving_data = {'y_true':global_true, 'y_pred':global_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d6e76b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.22      0.13      0.16       521\n",
      "      Normal       0.93      0.96      0.94      6175\n",
      "\n",
      "    accuracy                           0.90      6696\n",
      "   macro avg       0.57      0.55      0.55      6696\n",
      "weighted avg       0.87      0.90      0.88      6696\n",
      "\n",
      "0.8959080047789725\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ad_predictions, ad_true))\n",
    "print(accuracy_score(ad_predictions, ad_true))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
