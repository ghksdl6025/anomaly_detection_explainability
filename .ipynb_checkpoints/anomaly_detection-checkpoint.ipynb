{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc129d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import json\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34472358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_prefix(df,prefix):\n",
    "    '''\n",
    "    Filter case by prefix length\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to slice by prefix length\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe with sliced cases\n",
    "    '''\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    for case,group in groups: \n",
    "        group = group.reset_index(drop=True)\n",
    "        if len(group)>prefix:\n",
    "            group = group.loc[:prefix-1,:]\n",
    "            encoded_df.append(group)\n",
    "    return pd.concat(encoded_df)\n",
    "\n",
    "def indexbase_encoding(df, prefix):\n",
    "    '''\n",
    "    Indexbase encoding\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas dataframe\n",
    "        Assigned dataframe to encode for outcome prediction\n",
    "    \n",
    "    prefix : int\n",
    "        Prefix length to slice to cases in fixed length\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Return dataframe encoded in indexbase method\n",
    "    '''\n",
    "    df = filter_by_prefix(df,prefix)\n",
    "    df['ts'] = pd.to_datetime(df['ts'])\n",
    "    groups = df.groupby('caseid')\n",
    "    encoded_df=[]\n",
    "    if 'resource' not in list(df.columns.values):\n",
    "        noresource = True\n",
    "    else:\n",
    "        noresource = False\n",
    "        \n",
    "    for case,group in groups: \n",
    "        activitylist = list(group['activity'])\n",
    "        \n",
    "        group = group.reset_index(drop=True)\n",
    "        outcome = set(group['outcome']).pop()\n",
    "        cumdurationlist = [(x - list(group['ts'])[0]).total_seconds() for x in list(group['ts'])]\n",
    "        cumduration_index ={'Cumduration_'+str(x+1): cumdurationlist[x] for x in range(len(cumdurationlist))}\n",
    "        \n",
    "        case_outcome = {'caseid':case, 'outcome':outcome}\n",
    "        activity_index = {'activity_'+str(x+1)+'_'+activitylist[x]: 1 for x in range(len(activitylist))}\n",
    "\n",
    "        if noresource == False:\n",
    "            resourcelist = list(group['resource'])\n",
    "            resource_index = {'resource_'+str(x+1)+'_'+str(resourcelist[x]): 1 for x in range(len(resourcelist))}\n",
    "            case_outcome.update(resource_index)\n",
    "        \n",
    "        case_outcome.update(cumduration_index)\n",
    "        case_outcome.update(activity_index)\n",
    "        dfk = pd.DataFrame.from_dict([case_outcome])\n",
    "        encoded_df.append(dfk)\n",
    "    concated_df = pd.concat(encoded_df)\n",
    "    concated_df = concated_df.fillna(0)\n",
    "    return concated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c9d6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./preprocessed_loan_baseline.pnml_noise_0.09999999999999999_iteration_1_seed_14329_sample.csv')\n",
    "used_models = 'XGB'\n",
    "\n",
    "\n",
    "key_pair = {'Case ID':'caseid', 'Activity':'activity', 'Complete Timestamp':'ts'}\n",
    "df = df.rename(columns=key_pair)\n",
    "\n",
    "if 'resource' in df.columns.values:\n",
    "    df = df.loc[:,['caseid','activity','ts','resource','noise']]\n",
    "\n",
    "else:\n",
    "    df = df.loc[:,['caseid','activity','ts','noise']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "744e33a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('caseid')\n",
    "concating = []\n",
    "max_case_len = max([len(group) for _, group in groups])\n",
    "caseids = list(set(df['caseid']))\n",
    "\n",
    "outcome = []\n",
    "for _, group in groups:\n",
    "    group = group.reset_index(drop=True)\n",
    "    actlist = list(group['activity'])\n",
    "    outcomelist = actlist[1:] + [np.nan]\n",
    "    group['outcome'] = outcomelist\n",
    "    concating.append(group)\n",
    "\n",
    "dfn = pd.concat(concating)\n",
    "\n",
    "max_case_len =15\n",
    "idslist = []\n",
    "for prefix in range(1, max_case_len):\n",
    "    idslist.append(indexbase_encoding(dfn,prefix))\n",
    "\n",
    "prefixlist= list(range(1, max_case_len))\n",
    "\n",
    "acc_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d197b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 500\n",
      "2 500\n",
      "3 500\n",
      "4 500\n",
      "5 500\n",
      "6 500\n",
      "7 500\n",
      "8 446\n",
      "9 402\n",
      "10 373\n",
      "11 318\n",
      "12 241\n",
      "13 201\n",
      "14 171\n"
     ]
    }
   ],
   "source": [
    "for pos, x in enumerate(idslist):\n",
    "    print(pos+1, len(set(x['caseid'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e59c574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB\n",
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:41:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "print(used_models)\n",
    "models = []\n",
    "testdf_list = []\n",
    "\n",
    "\n",
    "for pos,prefix in enumerate(idslist):  \n",
    "    caseids = list(set(prefix['caseid']))\n",
    "    trainids = np.random.choice(caseids, int(len(caseids)*0.7), replace=False)\n",
    "    traindf = prefix[prefix['caseid'].isin(trainids)].reset_index(drop=True)\n",
    "    testdf = prefix[~prefix['caseid'].isin(trainids)].reset_index(drop=True)\n",
    "    testdf_list.append(testdf)\n",
    "\n",
    "    y_train = traindf['outcome']\n",
    "    x_train = traindf.drop(columns=['outcome','caseid'],axis=1)\n",
    "\n",
    "    y_test = testdf['outcome']\n",
    "    x_test = testdf.drop(columns=['outcome','caseid'],axis=1)\n",
    "\n",
    "    # Random forest result    \n",
    "    \n",
    "    if used_models == 'RF':\n",
    "        m = RandomForestClassifier(n_estimators=10, criterion='entropy').fit(x_train,y_train)\n",
    "        y_pred = m.predict(x_test)\n",
    "\n",
    "    elif used_models =='XGB':\n",
    "        m = xgb.XGBClassifier(n_estimators = 20, learning_rate=0.01).fit(x_train, y_train)\n",
    "        y_pred = m.predict(x_test)\n",
    "        \n",
    "    models.append(m)\n",
    "\n",
    "    filename = './models/%s prefix %s.pkl'%(used_models, pos+1)\n",
    "    with open(filename,'wb') as f:\n",
    "        pkl.dump(m, f)\n",
    "\n",
    "    acc_dict['prefix_%s'%(str(prefixlist[pos]))] =  accuracy_score(y_test,y_pred)\n",
    "    \n",
    "    testids = list(set(testdf['caseid']))\n",
    "    test_file_name = './data/Prefix %s testdata.pkl'%(str(pos+1))\n",
    "    with open(test_file_name,'wb') as f:\n",
    "        pkl.dump(testids,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9fbedc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for_confusion_matrix = {}\n",
    "\n",
    "counting_normal = 0\n",
    "for threshold in [0.01,0.05,0.1,0.15,0.2,0.25]:\n",
    "    global_true =[]\n",
    "    global_pred = []\n",
    "    ad_predictions=[]\n",
    "    ad_true = []\n",
    "\n",
    "    for pos, prefix in enumerate(idslist):\n",
    "        testing_case_ids = set(testdf_list[-1]['caseid'])\n",
    "\n",
    "        prediction_list = []\n",
    "        testing_case_ids = set(testdf_list[pos]['caseid'])\n",
    "        for caseid in list(testing_case_ids):\n",
    "            prediction_label = 'Normal'\n",
    "            x_test = testdf_list[pos][testdf_list[pos]['caseid'] ==caseid]\n",
    "            true_outcome = x_test['outcome'].values[0]\n",
    "            \n",
    "            x_test_features = list(x_test.columns.values)\n",
    "            x_test_features.remove('caseid')\n",
    "            x_test_features.remove('outcome')\n",
    "            \n",
    "            x_test = x_test.loc[:, x_test_features]\n",
    "            x_test = np.array(x_test.values).reshape(1,-1)\n",
    "\n",
    "            model_classes = models[pos].classes_\n",
    "            predictions_proba = models[pos].predict_proba(x_test)[0]\n",
    "            predicted_one = model_classes[np.argmax(predictions_proba)]\n",
    "        \n",
    "            if predicted_one  == 'Not Available':\n",
    "                prediction_label = 'Not Available'\n",
    "            else:\n",
    "                if true_outcome in model_classes:\n",
    "                    labelidx = list(model_classes).index(true_outcome)\n",
    "\n",
    "                    if predictions_proba[labelidx] <threshold:\n",
    "                        prediction_label = 'Anomalous'\n",
    "                else:\n",
    "                    prediction_label = 'Anomalous'\n",
    "           \n",
    "            noisedf = df[df['caseid'] == caseid].reset_index(drop=True)\n",
    "            noiselabel = list(noisedf['noise'])[pos]\n",
    "            if np.isnan(noiselabel):\n",
    "                noiselabel= 'Normal'\n",
    "            else:\n",
    "                noiselabel= 'Anomalous'\n",
    "            ad_predictions.append(prediction_label)\n",
    "            ad_true.append(noiselabel)\n",
    "        \n",
    "    for_confusion_matrix[threshold]=[ad_predictions, ad_true]\n",
    "\n",
    "    # saving_data = {'y_true':global_true, 'y_pred':global_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d6e76b4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.31      0.03      0.05       176\n",
      "      Normal       0.90      0.99      0.94      1523\n",
      "\n",
      "    accuracy                           0.89      1699\n",
      "   macro avg       0.61      0.51      0.50      1699\n",
      "weighted avg       0.84      0.89      0.85      1699\n",
      "\n",
      "Accuarcy:  0.8928781636256622\n",
      "F1 score:  0.943231441048035\n",
      "{'Normal', 'Anomalous'} {'Normal', 'Anomalous'}\n",
      "0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.26      0.03      0.05       176\n",
      "      Normal       0.90      0.99      0.94      1523\n",
      "\n",
      "    accuracy                           0.89      1699\n",
      "   macro avg       0.58      0.51      0.50      1699\n",
      "weighted avg       0.83      0.89      0.85      1699\n",
      "\n",
      "Accuarcy:  0.8911124190700412\n",
      "F1 score:  0.9422416484545738\n",
      "{'Normal', 'Anomalous'} {'Normal', 'Anomalous'}\n",
      "0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.16      0.41      0.24       176\n",
      "      Normal       0.92      0.76      0.83      1523\n",
      "\n",
      "    accuracy                           0.72      1699\n",
      "   macro avg       0.54      0.59      0.53      1699\n",
      "weighted avg       0.84      0.72      0.77      1699\n",
      "\n",
      "Accuarcy:  0.7210123602118893\n",
      "F1 score:  0.8293736501079914\n",
      "{'Normal', 'Anomalous'} {'Normal', 'Anomalous'}\n",
      "0.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.14      0.73      0.23       176\n",
      "      Normal       0.94      0.46      0.62      1523\n",
      "\n",
      "    accuracy                           0.49      1699\n",
      "   macro avg       0.54      0.60      0.42      1699\n",
      "weighted avg       0.85      0.49      0.58      1699\n",
      "\n",
      "Accuarcy:  0.48793407886992346\n",
      "F1 score:  0.6167400881057269\n",
      "{'Normal', 'Anomalous'} {'Normal', 'Anomalous'}\n",
      "0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.10      1.00      0.19       176\n",
      "      Normal       0.00      0.00      0.00      1523\n",
      "\n",
      "    accuracy                           0.10      1699\n",
      "   macro avg       0.05      0.50      0.09      1699\n",
      "weighted avg       0.01      0.10      0.02      1699\n",
      "\n",
      "Accuarcy:  0.10359034726309593\n",
      "F1 score:  0.0\n",
      "{'Anomalous'} {'Normal', 'Anomalous'}\n",
      "0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Anomalous       0.10      1.00      0.19       176\n",
      "      Normal       0.00      0.00      0.00      1523\n",
      "\n",
      "    accuracy                           0.10      1699\n",
      "   macro avg       0.05      0.50      0.09      1699\n",
      "weighted avg       0.01      0.10      0.02      1699\n",
      "\n",
      "Accuarcy:  0.10359034726309593\n",
      "F1 score:  0.0\n",
      "{'Anomalous'} {'Normal', 'Anomalous'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\python3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for t in for_confusion_matrix.keys():\n",
    "    print(t)\n",
    "    predictions = for_confusion_matrix[t][0]\n",
    "    trues = for_confusion_matrix[t][1]\n",
    "    print(classification_report(y_pred = predictions, y_true = trues))\n",
    "    print('Accuarcy: ',accuracy_score(y_pred = predictions, y_true = trues))\n",
    "    print('F1 score: ',f1_score(y_pred = predictions, y_true = trues, average='binary', pos_label='Normal'))\n",
    "    print(set(predictions), set(trues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8374e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
